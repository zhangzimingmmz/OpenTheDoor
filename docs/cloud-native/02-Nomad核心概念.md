# ğŸ“š Nomad æ ¸å¿ƒæ¦‚å¿µ

## ğŸ“– æ¦‚è¿°

æ·±å…¥ç†è§£ Nomad çš„æ ¸å¿ƒæ¦‚å¿µæ˜¯æŒæ¡ Nomad çš„å…³é”®ã€‚æœ¬ç« è¯¦ç»†è®²è§£ Jobã€Task Groupã€Taskã€Allocation ç­‰æ ¸å¿ƒç»„ä»¶ã€‚

---

## ğŸ¯ æ ¸å¿ƒæ¦‚å¿µå±‚çº§

```
Job (ä½œä¸š)
  â””â”€â”€ Task Group (ä»»åŠ¡ç»„)
        â”œâ”€â”€ Task 1 (ä»»åŠ¡1)
        â”œâ”€â”€ Task 2 (ä»»åŠ¡2)
        â””â”€â”€ Network (ç½‘ç»œ)
              â”œâ”€â”€ Allocation 1 (å®ä¾‹1)
              â””â”€â”€ Allocation 2 (å®ä¾‹2)
```

---

## ğŸ“¦ Job (ä½œä¸š)

### ä»€ä¹ˆæ˜¯ Jobï¼Ÿ

**Job** æ˜¯ Nomad çš„**åŸºæœ¬è°ƒåº¦å•å…ƒ**ï¼Œå®šä¹‰äº†éœ€è¦è¿è¡Œçš„å·¥ä½œè´Ÿè½½ã€‚

### Job çš„ç»„æˆ

```hcl
job "my-app" {
  # åŸºæœ¬å±æ€§
  datacenters = ["dc1", "dc2"]  # æ•°æ®ä¸­å¿ƒ
  type        = "service"        # ç±»å‹
  priority    = 50               # ä¼˜å…ˆçº§ï¼ˆ1-100ï¼‰
  
  # æ›´æ–°ç­–ç•¥
  update {
    max_parallel = 2
    stagger      = "30s"
  }
  
  # ä»»åŠ¡ç»„
  group "web" {
    # ...
  }
}
```

### Job ç±»å‹ï¼ˆTypeï¼‰

#### 1ï¸âƒ£ Serviceï¼ˆæœåŠ¡å‹ï¼‰

**ç‰¹ç‚¹**ï¼š
- é•¿æœŸè¿è¡Œçš„æœåŠ¡
- è‡ªåŠ¨é‡å¯å¤±è´¥çš„ä»»åŠ¡
- æ”¯æŒæ»šåŠ¨æ›´æ–°

**é€‚ç”¨åœºæ™¯**ï¼š
- Web æœåŠ¡
- API æœåŠ¡
- æ•°æ®åº“
- æ¶ˆæ¯é˜Ÿåˆ—

**ç¤ºä¾‹**ï¼š

```hcl
job "web-server" {
  type = "service"
  
  group "web" {
    count = 3  # è¿è¡Œ 3 ä¸ªå®ä¾‹
    
    task "nginx" {
      driver = "docker"
      
      config {
        image = "nginx:latest"
        ports = ["http"]
      }
      
      resources {
        cpu    = 500
        memory = 256
      }
    }
  }
}
```

#### 2ï¸âƒ£ Batchï¼ˆæ‰¹å¤„ç†å‹ï¼‰

**ç‰¹ç‚¹**ï¼š
- è¿è¡Œå®Œæˆåé€€å‡º
- ä¸è‡ªåŠ¨é‡å¯
- é€‚åˆä¸€æ¬¡æ€§ä»»åŠ¡

**é€‚ç”¨åœºæ™¯**ï¼š
- æ•°æ®å¤„ç†
- æŠ¥è¡¨ç”Ÿæˆ
- å¤‡ä»½ä»»åŠ¡
- ETL ä»»åŠ¡

**ç¤ºä¾‹**ï¼š

```hcl
job "data-import" {
  type = "batch"
  
  group "import" {
    task "import-script" {
      driver = "docker"
      
      config {
        image = "python:3.9"
        command = "python"
        args = ["import.py"]
      }
      
      resources {
        cpu    = 1000
        memory = 1024
      }
    }
  }
}
```

#### 3ï¸âƒ£ Systemï¼ˆç³»ç»Ÿå‹ï¼‰

**ç‰¹ç‚¹**ï¼š
- æ¯ä¸ª Client èŠ‚ç‚¹è¿è¡Œä¸€ä¸ªå®ä¾‹
- ç±»ä¼¼ Kubernetes çš„ DaemonSet
- èŠ‚ç‚¹åŠ å…¥æ—¶è‡ªåŠ¨éƒ¨ç½²

**é€‚ç”¨åœºæ™¯**ï¼š
- æ—¥å¿—æ”¶é›†
- ç›‘æ§ Agent
- ç½‘ç»œä»£ç†
- å®‰å…¨æ‰«æ

**ç¤ºä¾‹**ï¼š

```hcl
job "monitoring-agent" {
  type = "system"
  
  group "agent" {
    task "node-exporter" {
      driver = "docker"
      
      config {
        image = "prom/node-exporter:latest"
        network_mode = "host"
      }
      
      resources {
        cpu    = 100
        memory = 128
      }
    }
  }
}
```

### Job ä¼˜å…ˆçº§ï¼ˆPriorityï¼‰

```hcl
job "critical-service" {
  # ä¼˜å…ˆçº§ï¼š1-100ï¼Œæ•°å€¼è¶Šå¤§ä¼˜å…ˆçº§è¶Šé«˜
  priority = 80
  
  # é«˜ä¼˜å…ˆçº§çš„ Job ä¼šä¼˜å…ˆè·å¾—èµ„æº
  # åœ¨èµ„æºç´§å¼ æ—¶ï¼Œä½ä¼˜å…ˆçº§çš„ Job å¯èƒ½è¢«æŠ¢å 
}
```

---

## ğŸ‘¥ Task Group (ä»»åŠ¡ç»„)

### ä»€ä¹ˆæ˜¯ Task Groupï¼Ÿ

**Task Group** æ˜¯ä¸€ç»„**ç›¸å…³ä»»åŠ¡çš„é›†åˆ**ï¼Œç±»ä¼¼ Kubernetes çš„ Podã€‚

### ç‰¹ç‚¹

- åŒä¸€ Task Group å†…çš„ä»»åŠ¡**è¿è¡Œåœ¨åŒä¸€èŠ‚ç‚¹**
- å…±äº«ç½‘ç»œå‘½åç©ºé—´
- å…±äº«å­˜å‚¨å·
- ä½œä¸ºä¸€ä¸ªæ•´ä½“è¿›è¡Œè°ƒåº¦

### åŸºæœ¬é…ç½®

```hcl
group "cache" {
  # å®ä¾‹æ•°é‡
  count = 3
  
  # é‡å¯ç­–ç•¥
  restart {
    attempts = 3
    interval = "5m"
    delay    = "25s"
    mode     = "fail"
  }
  
  # æ›´æ–°ç­–ç•¥
  update {
    max_parallel     = 1
    health_check     = "checks"
    min_healthy_time = "10s"
    healthy_deadline = "5m"
  }
  
  # ä»»åŠ¡å®šä¹‰
  task "redis" {
    # ...
  }
  
  task "sidecar" {
    # ...
  }
}
```

### çº¦æŸæ¡ä»¶ï¼ˆConstraintsï¼‰

```hcl
group "gpu-task" {
  # å¿…é¡»æœ‰ GPU
  constraint {
    attribute = "${attr.gpu.present}"
    value     = "true"
  }
  
  # åªåœ¨ç‰¹å®šæ•°æ®ä¸­å¿ƒ
  constraint {
    attribute = "${node.datacenter}"
    value     = "dc1"
  }
  
  # é¿å…ç‰¹å®šèŠ‚ç‚¹ç±»åˆ«
  constraint {
    attribute = "${node.class}"
    operator  = "!="
    value     = "spot"
  }
}
```

### äº²å’Œæ€§ï¼ˆAffinityï¼‰

```hcl
group "web" {
  # è½¯çº¦æŸï¼šä¼˜å…ˆé€‰æ‹©æœ‰ SSD çš„èŠ‚ç‚¹
  affinity {
    attribute = "${meta.storage_type}"
    value     = "ssd"
    weight    = 75  # æƒé‡ï¼š-100 åˆ° 100
  }
  
  # ä¼˜å…ˆé€‰æ‹© CPU è¾ƒå¤šçš„èŠ‚ç‚¹
  affinity {
    attribute = "${attr.cpu.numcores}"
    operator  = ">"
    value     = "4"
    weight    = 50
  }
}
```

### åäº²å’Œæ€§ï¼ˆSpreadï¼‰

```hcl
group "database" {
  # è·¨èŠ‚ç‚¹åˆ†å¸ƒï¼ˆé«˜å¯ç”¨ï¼‰
  spread {
    attribute = "${node.unique.id}"
    weight    = 100
  }
  
  # è·¨æœºæ¶åˆ†å¸ƒ
  spread {
    attribute = "${meta.rack}"
    weight    = 50
  }
}
```

---

## âš™ï¸ Task (ä»»åŠ¡)

### ä»€ä¹ˆæ˜¯ Taskï¼Ÿ

**Task** æ˜¯ Nomad ä¸­çš„**æœ€å°æ‰§è¡Œå•å…ƒ**ï¼Œå®šä¹‰äº†å…·ä½“è¦è¿è¡Œçš„å·¥ä½œã€‚

### åŸºæœ¬é…ç½®

```hcl
task "web-server" {
  # é©±åŠ¨ç±»å‹
  driver = "docker"
  
  # é©±åŠ¨é…ç½®
  config {
    image = "nginx:alpine"
    ports = ["http", "https"]
    
    volumes = [
      "/host/path:/container/path"
    ]
  }
  
  # ç¯å¢ƒå˜é‡
  env {
    APP_ENV = "production"
    LOG_LEVEL = "info"
  }
  
  # èµ„æºéœ€æ±‚
  resources {
    cpu    = 500   # MHz
    memory = 256   # MB
    
    network {
      mbits = 10
      port "http" {
        static = 80
      }
      port "https" {
        static = 443
      }
    }
  }
  
  # æœåŠ¡æ³¨å†Œ
  service {
    name = "nginx"
    port = "http"
  }
}
```

---

## ğŸš— Driver (é©±åŠ¨)

### æ”¯æŒçš„é©±åŠ¨ç±»å‹

#### 1ï¸âƒ£ Docker é©±åŠ¨

```hcl
task "app" {
  driver = "docker"
  
  config {
    image = "myapp:latest"
    
    # ç«¯å£æ˜ å°„
    ports = ["http"]
    
    # å·æŒ‚è½½
    volumes = [
      "/data:/app/data",
      "secrets:/app/secrets:ro"
    ]
    
    # èµ„æºé™åˆ¶
    cpu_hard_limit = true
    memory_hard_limit = 512
    
    # æ—¥å¿—é…ç½®
    logging {
      type = "json-file"
      config {
        max-size = "10m"
        max-file = "3"
      }
    }
    
    # å¥åº·æ£€æŸ¥
    healthchecks {
      disable = false
    }
  }
}
```

#### 2ï¸âƒ£ Exec é©±åŠ¨

```hcl
task "script" {
  driver = "exec"
  
  config {
    command = "/bin/bash"
    args    = ["-c", "echo Hello World"]
  }
}
```

#### 3ï¸âƒ£ Java é©±åŠ¨

```hcl
task "java-app" {
  driver = "java"
  
  config {
    jar_path    = "local/app.jar"
    jvm_options = ["-Xmx512m", "-Xms256m"]
    args        = ["--spring.profiles.active=prod"]
  }
}
```

#### 4ï¸âƒ£ Raw Exec é©±åŠ¨

```hcl
task "binary" {
  driver = "raw_exec"
  
  config {
    command = "/usr/local/bin/myapp"
    args    = ["--config", "/etc/myapp.conf"]
  }
}
```

---

## ğŸ“Œ Allocation (åˆ†é…)

### ä»€ä¹ˆæ˜¯ Allocationï¼Ÿ

**Allocation** æ˜¯ Task Group åœ¨æŸä¸ªèŠ‚ç‚¹ä¸Šçš„**å®é™…è¿è¡Œå®ä¾‹**ã€‚

### ç”Ÿå‘½å‘¨æœŸ

```
Pending â†’ Running â†’ Complete/Failed
```

#### çŠ¶æ€è¯´æ˜

| çŠ¶æ€ | è¯´æ˜ |
|:---|:---|
| **pending** | ç­‰å¾…è°ƒåº¦ |
| **running** | æ­£åœ¨è¿è¡Œ |
| **complete** | æˆåŠŸå®Œæˆï¼ˆbatch ç±»å‹ï¼‰|
| **failed** | è¿è¡Œå¤±è´¥ |
| **lost** | èŠ‚ç‚¹å¤±è” |

### æŸ¥çœ‹ Allocation

```bash
# åˆ—å‡ºæ‰€æœ‰ Allocation
nomad alloc status

# æŸ¥çœ‹ç‰¹å®š Allocation
nomad alloc status <alloc-id>

# æŸ¥çœ‹æ—¥å¿—
nomad alloc logs <alloc-id>

# è¿›å…¥å®¹å™¨
nomad alloc exec <alloc-id> /bin/sh
```

---

## ğŸ”„ Evaluation (è¯„ä¼°)

### ä»€ä¹ˆæ˜¯ Evaluationï¼Ÿ

**Evaluation** æ˜¯ Nomad çš„**è°ƒåº¦å†³ç­–è¿‡ç¨‹**ã€‚

### è§¦å‘åœºæ™¯

- æäº¤æ–° Job
- æ›´æ–°ç°æœ‰ Job
- èŠ‚ç‚¹çŠ¶æ€å˜åŒ–
- Allocation å¤±è´¥

### æŸ¥çœ‹ Evaluation

```bash
# æŸ¥çœ‹ Evaluation çŠ¶æ€
nomad eval status <eval-id>

# è¾“å‡ºç¤ºä¾‹ï¼š
# ID                  = abc123
# Status              = complete
# Type                = service
# TriggeredBy         = job-register
# Job ID              = my-app
# Priority            = 50
# Placement Failures  = false
```

---

## ğŸ” æ›´æ–°ç­–ç•¥ï¼ˆUpdate Strategyï¼‰

### æ»šåŠ¨æ›´æ–°

```hcl
job "web" {
  update {
    # æ¯æ¬¡æ›´æ–°çš„å¹¶è¡Œæ•°
    max_parallel = 2
    
    # å¥åº·æ£€æŸ¥
    health_check = "checks"
    
    # æœ€å°å¥åº·æ—¶é—´
    min_healthy_time = "10s"
    
    # å¥åº·æ£€æŸ¥è¶…æ—¶
    healthy_deadline = "5m"
    
    # è‡ªåŠ¨å›æ»š
    auto_revert = true
    
    # è‡ªåŠ¨æå‡ï¼ˆCanaryï¼‰
    auto_promote = false
    
    # Canary æ•°é‡
    canary = 1
  }
}
```

### Canary éƒ¨ç½²

```hcl
job "api" {
  group "api-server" {
    count = 10
    
    update {
      # å…ˆéƒ¨ç½² 2 ä¸ª Canary å®ä¾‹
      canary = 2
      
      # æ‰‹åŠ¨æå‡
      auto_promote = false
      
      # å¥åº·æ£€æŸ¥
      health_check = "checks"
      min_healthy_time = "30s"
    }
  }
}
```

**æ“ä½œæµç¨‹**ï¼š

```bash
# 1. æäº¤æ›´æ–°
nomad job run app.nomad.hcl

# 2. è§‚å¯Ÿ Canary
nomad deployment status <deployment-id>

# 3. æ‰‹åŠ¨æå‡ï¼ˆå¦‚æœ Canary æ­£å¸¸ï¼‰
nomad deployment promote <deployment-id>

# 4. æˆ–è€…å›æ»š
nomad deployment fail <deployment-id>
```

---

## ğŸ“Š èµ„æºè°ƒåº¦

### èµ„æºç±»å‹

```hcl
resources {
  # CPUï¼ˆMHzï¼‰
  cpu    = 500
  
  # å†…å­˜ï¼ˆMBï¼‰
  memory = 256
  
  # ç½‘ç»œå¸¦å®½ï¼ˆMbpsï¼‰
  network {
    mbits = 10
  }
  
  # è®¾å¤‡ï¼ˆGPUç­‰ï¼‰
  device "nvidia/gpu" {
    count = 1
    
    constraint {
      attribute = "${device.attr.memory}"
      operator  = ">"
      value     = "8GB"
    }
  }
}
```

### èµ„æºè¶…å”®ï¼ˆOversubscriptionï¼‰

```hcl
task "app" {
  resources {
    cpu    = 500
    memory = 256
    
    # å†…å­˜è¶…å”®ä¿ç•™
    memory_max = 512
  }
}
```

---

## ğŸ¯ æœ¬ç« å°ç»“

- âœ… ç†è§£ Jobã€Task Groupã€Task çš„å±‚çº§å…³ç³»
- âœ… æŒæ¡ Serviceã€Batchã€System ä¸‰ç§ Job ç±»å‹
- âœ… å­¦ä¼šä½¿ç”¨çº¦æŸå’Œäº²å’Œæ€§æ§åˆ¶è°ƒåº¦
- âœ… äº†è§£ Allocation å’Œ Evaluation çš„ä½œç”¨
- âœ… æŒæ¡æ›´æ–°ç­–ç•¥å’Œ Canary éƒ¨ç½²

---

## ğŸ“š ä¸‹ä¸€æ­¥å­¦ä¹ 

- ğŸ—ï¸ [03-Nomadå®æˆ˜éƒ¨ç½²](03-Nomadå®æˆ˜éƒ¨ç½².md) - æ­å»ºç”Ÿäº§çº§é›†ç¾¤
- ğŸ”§ [04-Nomadä½œä¸šç¼–æ’](04-Nomadä½œä¸šç¼–æ’.md) - å¤æ‚ Job é…ç½®
- ğŸŒ [05-Nomadç½‘ç»œä¸æœåŠ¡å‘ç°](05-Nomadç½‘ç»œä¸æœåŠ¡å‘ç°.md) - ç½‘ç»œå’Œ Consul é›†æˆ

---

ğŸ”„ æŒç»­æ›´æ–°ä¸­... | æœ€åæ›´æ–°ï¼š2025å¹´10æœˆ

