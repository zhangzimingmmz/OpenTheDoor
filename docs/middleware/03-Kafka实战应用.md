# Kafka å®æˆ˜åº”ç”¨

## ğŸ“– ç›®å½•

- [1. Spring Boot é›†æˆ Kafka](#1-spring-boot-é›†æˆ-kafka)
- [2. å®é™…ä¸šåŠ¡åœºæ™¯åº”ç”¨](#2-å®é™…ä¸šåŠ¡åœºæ™¯åº”ç”¨)
- [3. æ¶ˆæ¯åºåˆ—åŒ–ä¸ååºåˆ—åŒ–](#3-æ¶ˆæ¯åºåˆ—åŒ–ä¸ååºåˆ—åŒ–)
- [4. é”™è¯¯å¤„ç†ä¸é‡è¯•æœºåˆ¶](#4-é”™è¯¯å¤„ç†ä¸é‡è¯•æœºåˆ¶)
- [5. ç›‘æ§ä¸è¿ç»´](#5-ç›‘æ§ä¸è¿ç»´)
- [6. æœ€ä½³å®è·µ](#6-æœ€ä½³å®è·µ)
- [7. å¸¸è§é¢è¯•é¢˜](#7-å¸¸è§é¢è¯•é¢˜)

---

## 1. Spring Boot é›†æˆ Kafka

### 1.1 æ·»åŠ ä¾èµ–

#### 1.1.1 Maven ä¾èµ–

```xml
<dependencies>
    <!-- Spring Boot Kafka Starter -->
    <dependency>
        <groupId>org.springframework.kafka</groupId>
        <artifactId>spring-kafka</artifactId>
    </dependency>
    
    <!-- Spring Boot Webï¼ˆå¦‚æœéœ€è¦ REST APIï¼‰ -->
    <dependency>
        <groupId>org.springframework.boot</groupId>
        <artifactId>spring-boot-starter-web</artifactId>
    </dependency>
    
    <!-- JSON åºåˆ—åŒ–ï¼ˆå¦‚æœéœ€è¦ï¼‰ -->
    <dependency>
            <groupId>org.springframework.kafka</groupId>
            <artifactId>spring-kafka</artifactId>
    </dependency>
</dependencies>
```

#### 1.1.2 Gradle ä¾èµ–

```gradle
dependencies {
    implementation 'org.springframework.kafka:spring-kafka'
    implementation 'org.springframework.boot:spring-boot-starter-web'
}
```

### 1.2 é…ç½®æ–‡ä»¶

#### 1.2.1 application.yml

```yaml
spring:
  kafka:
    # Broker åœ°å€
    bootstrap-servers: localhost:9092
    
    # Producer é…ç½®
    producer:
      # Key åºåˆ—åŒ–å™¨
      key-serializer: org.apache.kafka.common.serialization.StringSerializer
      # Value åºåˆ—åŒ–å™¨
      value-serializer: org.apache.kafka.common.serialization.StringSerializer
      # æ¶ˆæ¯ç¡®è®¤æœºåˆ¶
      acks: all
      # é‡è¯•æ¬¡æ•°
      retries: 3
      # æ‰¹æ¬¡å¤§å°ï¼ˆå­—èŠ‚ï¼‰
      batch-size: 32768
      # ç­‰å¾…æ—¶é—´ï¼ˆæ¯«ç§’ï¼‰
      linger-ms: 10
      # ç¼“å†²åŒºå¤§å°ï¼ˆå­—èŠ‚ï¼‰
      buffer-memory: 67108864
      # å‹ç¼©ç±»å‹
      compression-type: snappy
      # å¹‚ç­‰æ€§
      enable-idempotence: true
    
    # Consumer é…ç½®
    consumer:
      # Consumer Group ID
      group-id: my-consumer-group
      # Key ååºåˆ—åŒ–å™¨
      key-deserializer: org.apache.kafka.common.serialization.StringDeserializer
      # Value ååºåˆ—åŒ–å™¨
      value-deserializer: org.apache.kafka.common.serialization.StringDeserializer
      # åç§»é‡é‡ç½®ç­–ç•¥
      auto-offset-reset: earliest
      # æ˜¯å¦è‡ªåŠ¨æäº¤ Offset
      enable-auto-commit: false
      # æ¯æ¬¡æ‹‰å–çš„æœ€å¤§è®°å½•æ•°
      max-poll-records: 500
      # æœ€å¤§æ‹‰å–é—´éš”ï¼ˆæ¯«ç§’ï¼‰
      max-poll-interval-ms: 300000
    
    # Listener é…ç½®
    listener:
      # ç¡®è®¤æ¨¡å¼ï¼ˆmanual - æ‰‹åŠ¨æäº¤ï¼Œbatch - æ‰¹é‡æäº¤ï¼‰
      ack-mode: manual_immediate
      # å¹¶å‘æ¶ˆè´¹è€…æ•°é‡
      concurrency: 3
```

#### 1.2.2 application.properties

```properties
# Kafka Broker åœ°å€
spring.kafka.bootstrap-servers=localhost:9092

# Producer é…ç½®
spring.kafka.producer.key-serializer=org.apache.kafka.common.serialization.StringSerializer
spring.kafka.producer.value-serializer=org.apache.kafka.common.serialization.StringSerializer
spring.kafka.producer.acks=all
spring.kafka.producer.retries=3
spring.kafka.producer.batch-size=32768
spring.kafka.producer.linger-ms=10
spring.kafka.producer.buffer-memory=67108864
spring.kafka.producer.compression-type=snappy
spring.kafka.producer.enable-idempotence=true

# Consumer é…ç½®
spring.kafka.consumer.group-id=my-consumer-group
spring.kafka.consumer.key-deserializer=org.apache.kafka.common.serialization.StringDeserializer
spring.kafka.consumer.value-deserializer=org.apache.kafka.common.serialization.StringDeserializer
spring.kafka.consumer.auto-offset-reset=earliest
spring.kafka.consumer.enable-auto-commit=false
spring.kafka.consumer.max-poll-records=500
spring.kafka.consumer.max-poll-interval-ms=300000

# Listener é…ç½®
spring.kafka.listener.ack-mode=manual_immediate
spring.kafka.listener.concurrency=3
```

### 1.3 Producer ä½¿ç”¨

#### 1.3.1 æ³¨å…¥ KafkaTemplate

```java
import org.springframework.beans.factory.annotation.Autowired;
import org.springframework.kafka.core.KafkaTemplate;
import org.springframework.kafka.support.SendResult;
import org.springframework.stereotype.Service;
import org.springframework.util.concurrent.ListenableFuture;
import org.springframework.util.concurrent.ListenableFutureCallback;

/**
 * Kafka Producer æœåŠ¡
 * Kafka Producer Service
 */
@Service
public class KafkaProducerService {
    
    @Autowired
    private KafkaTemplate<String, String> kafkaTemplate;
    
    /**
     * å‘é€æ¶ˆæ¯ï¼ˆå¼‚æ­¥ï¼‰
     * Send message asynchronously
     */
    public void sendMessage(String topic, String key, String message) {
        ListenableFuture<SendResult<String, String>> future = 
            kafkaTemplate.send(topic, key, message);
        
        future.addCallback(new ListenableFutureCallback<SendResult<String, String>>() {
            @Override
            public void onSuccess(SendResult<String, String> result) {
                System.out.println("æ¶ˆæ¯å‘é€æˆåŠŸ: " + 
                    "topic=" + result.getRecordMetadata().topic() + 
                    ", partition=" + result.getRecordMetadata().partition() + 
                    ", offset=" + result.getRecordMetadata().offset());
            }
            
            @Override
            public void onFailure(Throwable ex) {
                System.err.println("æ¶ˆæ¯å‘é€å¤±è´¥: " + ex.getMessage());
            }
        });
    }
    
    /**
     * å‘é€æ¶ˆæ¯ï¼ˆåŒæ­¥ï¼‰
     * Send message synchronously
     */
    public void sendMessageSync(String topic, String key, String message) {
        try {
            SendResult<String, String> result = 
                kafkaTemplate.send(topic, key, message).get();
            System.out.println("æ¶ˆæ¯å‘é€æˆåŠŸ: " + result.getRecordMetadata().offset());
        } catch (Exception e) {
            System.err.println("æ¶ˆæ¯å‘é€å¤±è´¥: " + e.getMessage());
        }
    }
}
```

#### 1.3.2 REST API ç¤ºä¾‹

```java
import org.springframework.beans.factory.annotation.Autowired;
import org.springframework.web.bind.annotation.PostMapping;
import org.springframework.web.bind.annotation.RequestBody;
import org.springframework.web.bind.annotation.RequestMapping;
import org.springframework.web.bind.annotation.RestController;

/**
 * Kafka æ¶ˆæ¯å‘é€æ§åˆ¶å™¨
 * Kafka Message Producer Controller
 */
@RestController
@RequestMapping("/api/kafka")
public class KafkaController {
    
    @Autowired
    private KafkaProducerService kafkaProducerService;
    
    @PostMapping("/send")
    public String sendMessage(@RequestBody MessageRequest request) {
        kafkaProducerService.sendMessage(
            request.getTopic(),
            request.getKey(),
            request.getMessage()
        );
        return "æ¶ˆæ¯å·²å‘é€";
    }
    
    // æ¶ˆæ¯è¯·æ±‚ DTO
    public static class MessageRequest {
        private String topic;
        private String key;
        private String message;
        
        // Getters and Setters
        public String getTopic() { return topic; }
        public void setTopic(String topic) { this.topic = topic; }
        public String getKey() { return key; }
        public void setKey(String key) { this.key = key; }
        public String getMessage() { return message; }
        public void setMessage(String message) { this.message = message; }
    }
}
```

### 1.4 Consumer ä½¿ç”¨

#### 1.4.1 @KafkaListener æ³¨è§£

```java
import org.apache.kafka.clients.consumer.ConsumerRecord;
import org.springframework.kafka.annotation.KafkaListener;
import org.springframework.kafka.support.Acknowledgment;
import org.springframework.kafka.support.KafkaHeaders;
import org.springframework.messaging.handler.annotation.Header;
import org.springframework.messaging.handler.annotation.Payload;
import org.springframework.stereotype.Component;

/**
 * Kafka Consumer æœåŠ¡
 * Kafka Consumer Service
 */
@Component
public class KafkaConsumerService {
    
    /**
     * æ¶ˆè´¹æ¶ˆæ¯ï¼ˆè‡ªåŠ¨æäº¤ Offsetï¼‰
     * Consume message with auto commit
     */
    @KafkaListener(topics = "orders", groupId = "order-consumer-group")
    public void consumeOrderMessage(@Payload String message,
                                    @Header(KafkaHeaders.RECEIVED_TOPIC) String topic,
                                    @Header(KafkaHeaders.RECEIVED_PARTITION_ID) int partition,
                                    @Header(KafkaHeaders.OFFSET) long offset) {
        System.out.printf("æ”¶åˆ°æ¶ˆæ¯: topic=%s, partition=%d, offset=%d, message=%s%n",
            topic, partition, offset, message);
        
        // ä¸šåŠ¡å¤„ç†
        processOrderMessage(message);
    }
    
    /**
     * æ¶ˆè´¹æ¶ˆæ¯ï¼ˆæ‰‹åŠ¨æäº¤ Offsetï¼‰
     * Consume message with manual commit
     */
    @KafkaListener(topics = "payments", groupId = "payment-consumer-group")
    public void consumePaymentMessage(ConsumerRecord<String, String> record,
                                      Acknowledgment acknowledgment) {
        try {
            System.out.printf("æ”¶åˆ°æ¶ˆæ¯: topic=%s, partition=%d, offset=%d, key=%s, value=%s%n",
                record.topic(), record.partition(), record.offset(),
                record.key(), record.value());
            
            // ä¸šåŠ¡å¤„ç†
            processPaymentMessage(record.value());
            
            // æ‰‹åŠ¨æäº¤ Offset
            acknowledgment.acknowledge();
        } catch (Exception e) {
            System.err.println("å¤„ç†æ¶ˆæ¯å¤±è´¥: " + e.getMessage());
            // ä¸æäº¤ Offsetï¼Œæ¶ˆæ¯ä¼šé‡æ–°æ¶ˆè´¹
        }
    }
    
    /**
     * æ‰¹é‡æ¶ˆè´¹æ¶ˆæ¯
     * Batch consume messages
     */
    @KafkaListener(topics = "logs", groupId = "log-consumer-group",
                   containerFactory = "kafkaListenerContainerFactory")
    public void consumeLogMessages(@Payload List<String> messages,
                                  Acknowledgment acknowledgment) {
        try {
            for (String message : messages) {
                System.out.println("æ”¶åˆ°æ—¥å¿—æ¶ˆæ¯: " + message);
                processLogMessage(message);
            }
            
            // æ‰¹é‡æäº¤ Offset
            acknowledgment.acknowledge();
        } catch (Exception e) {
            System.err.println("å¤„ç†æ¶ˆæ¯å¤±è´¥: " + e.getMessage());
        }
    }
    
    // ä¸šåŠ¡å¤„ç†æ–¹æ³•
    private void processOrderMessage(String message) {
        // å¤„ç†è®¢å•æ¶ˆæ¯
        // Process order message
    }
    
    private void processPaymentMessage(String message) {
        // å¤„ç†æ”¯ä»˜æ¶ˆæ¯
        // Process payment message
    }
    
    private void processLogMessage(String message) {
        // å¤„ç†æ—¥å¿—æ¶ˆæ¯
        // Process log message
    }
}
```

#### 1.4.2 æ‰¹é‡æ¶ˆè´¹é…ç½®

```java
import org.apache.kafka.clients.consumer.ConsumerConfig;
import org.apache.kafka.common.serialization.StringDeserializer;
import org.springframework.context.annotation.Bean;
import org.springframework.context.annotation.Configuration;
import org.springframework.kafka.config.ConcurrentKafkaListenerContainerFactory;
import org.springframework.kafka.core.ConsumerFactory;
import org.springframework.kafka.core.DefaultKafkaConsumerFactory;
import org.springframework.kafka.listener.ContainerProperties;

import java.util.HashMap;
import java.util.Map;

/**
 * Kafka Consumer é…ç½®
 * Kafka Consumer Configuration
 */
@Configuration
public class KafkaConsumerConfig {
    
    @Bean
    public ConsumerFactory<String, String> consumerFactory() {
        Map<String, Object> props = new HashMap<>();
        props.put(ConsumerConfig.BOOTSTRAP_SERVERS_CONFIG, "localhost:9092");
        props.put(ConsumerConfig.GROUP_ID_CONFIG, "my-consumer-group");
        props.put(ConsumerConfig.KEY_DESERIALIZER_CLASS_CONFIG, StringDeserializer.class);
        props.put(ConsumerConfig.VALUE_DESERIALIZER_CLASS_CONFIG, StringDeserializer.class);
        props.put(ConsumerConfig.AUTO_OFFSET_RESET_CONFIG, "earliest");
        props.put(ConsumerConfig.ENABLE_AUTO_COMMIT_CONFIG, false);
        props.put(ConsumerConfig.MAX_POLL_RECORDS_CONFIG, 500); // æ‰¹é‡æ‹‰å–
        return new DefaultKafkaConsumerFactory<>(props);
    }
    
    @Bean
    public ConcurrentKafkaListenerContainerFactory<String, String> kafkaListenerContainerFactory() {
        ConcurrentKafkaListenerContainerFactory<String, String> factory =
            new ConcurrentKafkaListenerContainerFactory<>();
        factory.setConsumerFactory(consumerFactory());
        
        // è®¾ç½®æ‰¹é‡æ¶ˆè´¹
        factory.setBatchListener(true);
        
        // è®¾ç½®æ‰‹åŠ¨æäº¤
        factory.getContainerProperties().setAckMode(ContainerProperties.AckMode.MANUAL_IMMEDIATE);
        
        // è®¾ç½®å¹¶å‘æ¶ˆè´¹è€…æ•°é‡
        factory.setConcurrency(3);
        
        return factory;
    }
}
```

---

## 2. å®é™…ä¸šåŠ¡åœºæ™¯åº”ç”¨

### 2.1 è®¢å•ç³»ç»Ÿ

#### 2.1.1 åœºæ™¯æè¿°

è®¢å•åˆ›å»ºåï¼Œéœ€è¦ï¼š
1. å‘é€è®¢å•åˆ›å»ºäº‹ä»¶
2. åº“å­˜æœåŠ¡æ¶ˆè´¹äº‹ä»¶ï¼Œæ‰£å‡åº“å­˜
3. æ”¯ä»˜æœåŠ¡æ¶ˆè´¹äº‹ä»¶ï¼Œåˆ›å»ºæ”¯ä»˜è®¢å•
4. ç‰©æµæœåŠ¡æ¶ˆè´¹äº‹ä»¶ï¼Œåˆ›å»ºç‰©æµå•

#### 2.1.2 å®ç°ç¤ºä¾‹

**è®¢å•æœåŠ¡ï¼ˆProducerï¼‰**ï¼š

```java
import org.springframework.beans.factory.annotation.Autowired;
import org.springframework.kafka.core.KafkaTemplate;
import org.springframework.stereotype.Service;

/**
 * è®¢å•æœåŠ¡
 * Order Service
 */
@Service
public class OrderService {
    
    @Autowired
    private KafkaTemplate<String, String> kafkaTemplate;
    
    @Autowired
    private OrderRepository orderRepository;
    
    /**
     * åˆ›å»ºè®¢å•
     * Create order
     */
    public Order createOrder(OrderRequest request) {
        // 1. åˆ›å»ºè®¢å•
        Order order = new Order();
        order.setUserId(request.getUserId());
        order.setProductId(request.getProductId());
        order.setQuantity(request.getQuantity());
        order.setAmount(request.getAmount());
        order.setStatus("CREATED");
        order = orderRepository.save(order);
        
        // 2. å‘é€è®¢å•åˆ›å»ºäº‹ä»¶
        OrderEvent event = new OrderEvent();
        event.setOrderId(order.getId());
        event.setUserId(order.getUserId());
        event.setProductId(order.getProductId());
        event.setQuantity(order.getQuantity());
        event.setAmount(order.getAmount());
        event.setEventType("ORDER_CREATED");
        event.setTimestamp(System.currentTimeMillis());
        
        kafkaTemplate.send("order-events", order.getId().toString(), 
                          JSON.toJSONString(event));
        
        return order;
    }
}
```

**åº“å­˜æœåŠ¡ï¼ˆConsumerï¼‰**ï¼š

```java
import org.springframework.kafka.annotation.KafkaListener;
import org.springframework.kafka.support.Acknowledgment;
import org.springframework.stereotype.Service;

/**
 * åº“å­˜æœåŠ¡
 * Inventory Service
 */
@Service
public class InventoryService {
    
    @Autowired
    private InventoryRepository inventoryRepository;
    
    @KafkaListener(topics = "order-events", groupId = "inventory-service")
    public void handleOrderEvent(ConsumerRecord<String, String> record,
                                 Acknowledgment acknowledgment) {
        try {
            OrderEvent event = JSON.parseObject(record.value(), OrderEvent.class);
            
            if ("ORDER_CREATED".equals(event.getEventType())) {
                // æ‰£å‡åº“å­˜
                Inventory inventory = inventoryRepository.findByProductId(event.getProductId());
                if (inventory.getStock() >= event.getQuantity()) {
                    inventory.setStock(inventory.getStock() - event.getQuantity());
                    inventoryRepository.save(inventory);
                    
                    System.out.println("åº“å­˜æ‰£å‡æˆåŠŸ: productId=" + event.getProductId() + 
                                     ", quantity=" + event.getQuantity());
                } else {
                    throw new RuntimeException("åº“å­˜ä¸è¶³");
                }
            }
            
            // æäº¤ Offset
            acknowledgment.acknowledge();
        } catch (Exception e) {
            System.err.println("å¤„ç†è®¢å•äº‹ä»¶å¤±è´¥: " + e.getMessage());
            // ä¸æäº¤ Offsetï¼Œæ¶ˆæ¯ä¼šé‡æ–°æ¶ˆè´¹
        }
    }
}
```

### 2.2 æ—¥å¿—æ”¶é›†ç³»ç»Ÿ

#### 2.2.1 åœºæ™¯æè¿°

åº”ç”¨æ—¥å¿—å‘é€åˆ° Kafkaï¼Œç„¶åç”±æ—¥å¿—å¤„ç†æœåŠ¡æ¶ˆè´¹ï¼Œå­˜å‚¨åˆ° Elasticsearchã€‚

#### 2.2.2 å®ç°ç¤ºä¾‹

**æ—¥å¿—å‘é€ï¼ˆProducerï¼‰**ï¼š

```java
import org.slf4j.Logger;
import org.slf4j.LoggerFactory;
import org.springframework.kafka.core.KafkaTemplate;
import org.springframework.stereotype.Component;

/**
 * æ—¥å¿—å‘é€å™¨
 * Log Sender
 */
@Component
public class LogSender {
    
    private static final Logger logger = LoggerFactory.getLogger(LogSender.class);
    
    @Autowired
    private KafkaTemplate<String, String> kafkaTemplate;
    
    /**
     * å‘é€æ—¥å¿—
     * Send log
     */
    public void sendLog(String level, String message, String serviceName) {
        LogEvent logEvent = new LogEvent();
        logEvent.setLevel(level);
        logEvent.setMessage(message);
        logEvent.setServiceName(serviceName);
        logEvent.setTimestamp(System.currentTimeMillis());
        logEvent.setThreadName(Thread.currentThread().getName());
        
        kafkaTemplate.send("application-logs", serviceName, JSON.toJSONString(logEvent));
    }
}
```

**æ—¥å¿—å¤„ç†ï¼ˆConsumerï¼‰**ï¼š

```java
import org.springframework.kafka.annotation.KafkaListener;
import org.springframework.kafka.support.Acknowledgment;
import org.springframework.stereotype.Service;

/**
 * æ—¥å¿—å¤„ç†æœåŠ¡
 * Log Processing Service
 */
@Service
public class LogProcessingService {
    
    @Autowired
    private ElasticsearchService elasticsearchService;
    
    @KafkaListener(topics = "application-logs", groupId = "log-processing-service",
                   containerFactory = "kafkaListenerContainerFactory")
    public void processLogs(@Payload List<String> messages,
                            Acknowledgment acknowledgment) {
        try {
            List<LogEvent> logEvents = new ArrayList<>();
            for (String message : messages) {
                LogEvent logEvent = JSON.parseObject(message, LogEvent.class);
                logEvents.add(logEvent);
            }
            
            // æ‰¹é‡å­˜å‚¨åˆ° Elasticsearch
            elasticsearchService.bulkIndex(logEvents);
            
            // æäº¤ Offset
            acknowledgment.acknowledge();
        } catch (Exception e) {
            System.err.println("å¤„ç†æ—¥å¿—å¤±è´¥: " + e.getMessage());
        }
    }
}
```

---

## 3. æ¶ˆæ¯åºåˆ—åŒ–ä¸ååºåˆ—åŒ–

### 3.1 JSON åºåˆ—åŒ–

#### 3.1.1 é…ç½® JSON åºåˆ—åŒ–å™¨

```java
import org.apache.kafka.clients.producer.ProducerConfig;
import org.apache.kafka.clients.consumer.ConsumerConfig;
import org.apache.kafka.common.serialization.StringSerializer;
import org.apache.kafka.common.serialization.StringDeserializer;
import org.springframework.context.annotation.Bean;
import org.springframework.context.annotation.Configuration;
import org.springframework.kafka.core.DefaultKafkaProducerFactory;
import org.springframework.kafka.core.DefaultKafkaConsumerFactory;
import org.springframework.kafka.core.KafkaTemplate;
import org.springframework.kafka.core.ProducerFactory;
import org.springframework.kafka.core.ConsumerFactory;
import org.springframework.kafka.support.serializer.JsonSerializer;
import org.springframework.kafka.support.serializer.JsonDeserializer;

import java.util.HashMap;
import java.util.Map;

/**
 * Kafka JSON åºåˆ—åŒ–é…ç½®
 * Kafka JSON Serialization Configuration
 */
@Configuration
public class KafkaJsonConfig {
    
    @Bean
    public ProducerFactory<String, Object> producerFactory() {
        Map<String, Object> configProps = new HashMap<>();
        configProps.put(ProducerConfig.BOOTSTRAP_SERVERS_CONFIG, "localhost:9092");
        configProps.put(ProducerConfig.KEY_SERIALIZER_CLASS_CONFIG, StringSerializer.class);
        configProps.put(ProducerConfig.VALUE_SERIALIZER_CLASS_CONFIG, JsonSerializer.class);
        return new DefaultKafkaProducerFactory<>(configProps);
    }
    
    @Bean
    public KafkaTemplate<String, Object> kafkaTemplate() {
        return new KafkaTemplate<>(producerFactory());
    }
    
    @Bean
    public ConsumerFactory<String, Object> consumerFactory() {
        Map<String, Object> props = new HashMap<>();
        props.put(ConsumerConfig.BOOTSTRAP_SERVERS_CONFIG, "localhost:9092");
        props.put(ConsumerConfig.GROUP_ID_CONFIG, "my-consumer-group");
        props.put(ConsumerConfig.KEY_DESERIALIZER_CLASS_CONFIG, StringDeserializer.class);
        props.put(ConsumerConfig.VALUE_DESERIALIZER_CLASS_CONFIG, JsonDeserializer.class);
        props.put(JsonDeserializer.TRUSTED_PACKAGES, "*"); // ä¿¡ä»»æ‰€æœ‰åŒ…
        return new DefaultKafkaConsumerFactory<>(props);
    }
}
```

#### 3.2.2 ä½¿ç”¨ JSON åºåˆ—åŒ–

```java
import org.springframework.beans.factory.annotation.Autowired;
import org.springframework.kafka.core.KafkaTemplate;
import org.springframework.stereotype.Service;

/**
 * JSON æ¶ˆæ¯å‘é€ç¤ºä¾‹
 * JSON Message Send Example
 */
@Service
public class JsonMessageService {
    
    @Autowired
    private KafkaTemplate<String, Object> kafkaTemplate;
    
    /**
     * å‘é€ JSON æ¶ˆæ¯
     * Send JSON message
     */
    public void sendJsonMessage(OrderEvent event) {
        kafkaTemplate.send("order-events", event.getOrderId().toString(), event);
    }
}
```

```java
import org.springframework.kafka.annotation.KafkaListener;
import org.springframework.stereotype.Component;

/**
 * JSON æ¶ˆæ¯æ¶ˆè´¹ç¤ºä¾‹
 * JSON Message Consume Example
 */
@Component
public class JsonMessageConsumer {
    
    @KafkaListener(topics = "order-events", groupId = "order-consumer-group")
    public void consumeJsonMessage(OrderEvent event) {
        System.out.println("æ”¶åˆ°è®¢å•äº‹ä»¶: " + event);
        // å¤„ç†è®¢å•äº‹ä»¶
    }
}
```

### 3.2 Avro åºåˆ—åŒ–ï¼ˆé«˜çº§ï¼‰

Avro æ˜¯ä¸€ç§äºŒè¿›åˆ¶åºåˆ—åŒ–æ ¼å¼ï¼Œæ€§èƒ½ä¼˜äº JSONï¼Œé€‚åˆå¤§æ•°æ®åœºæ™¯ã€‚

**é…ç½®ç¤ºä¾‹**ï¼š

```java
import io.confluent.kafka.serializers.KafkaAvroSerializer;
import io.confluent.kafka.serializers.KafkaAvroDeserializer;

@Bean
public ProducerFactory<String, Object> avroProducerFactory() {
    Map<String, Object> configProps = new HashMap<>();
    configProps.put(ProducerConfig.BOOTSTRAP_SERVERS_CONFIG, "localhost:9092");
    configProps.put(ProducerConfig.KEY_SERIALIZER_CLASS_CONFIG, StringSerializer.class);
    configProps.put(ProducerConfig.VALUE_SERIALIZER_CLASS_CONFIG, KafkaAvroSerializer.class);
    configProps.put("schema.registry.url", "http://localhost:8081");
    return new DefaultKafkaProducerFactory<>(configProps);
}
```

---

## 4. é”™è¯¯å¤„ç†ä¸é‡è¯•æœºåˆ¶

### 4.1 é”™è¯¯å¤„ç†

#### 4.1.1 æ­»ä¿¡é˜Ÿåˆ—ï¼ˆDLQï¼‰

**é…ç½®æ­»ä¿¡é˜Ÿåˆ—**ï¼š

```java
import org.springframework.kafka.annotation.KafkaListener;
import org.springframework.kafka.core.KafkaTemplate;
import org.springframework.kafka.support.KafkaHeaders;
import org.springframework.messaging.handler.annotation.Header;
import org.springframework.stereotype.Component;

/**
 * é”™è¯¯å¤„ç†ç¤ºä¾‹
 * Error Handling Example
 */
@Component
public class ErrorHandlingConsumer {
    
    @Autowired
    private KafkaTemplate<String, String> kafkaTemplate;
    
    @KafkaListener(topics = "orders", groupId = "order-consumer-group")
    public void consumeOrder(ConsumerRecord<String, String> record,
                            Acknowledgment acknowledgment) {
        try {
            // å¤„ç†æ¶ˆæ¯
            processOrder(record.value());
            acknowledgment.acknowledge();
        } catch (Exception e) {
            System.err.println("å¤„ç†æ¶ˆæ¯å¤±è´¥: " + e.getMessage());
            
            // å‘é€åˆ°æ­»ä¿¡é˜Ÿåˆ—
            kafkaTemplate.send("orders-dlq", record.key(), record.value());
            
            // æäº¤ Offsetï¼Œé¿å…é‡å¤æ¶ˆè´¹
            acknowledgment.acknowledge();
        }
    }
    
    private void processOrder(String orderJson) {
        // ä¸šåŠ¡å¤„ç†
        // Business processing
    }
}
```

#### 4.1.2 é‡è¯•æœºåˆ¶

**é…ç½®é‡è¯•**ï¼š

```java
import org.springframework.context.annotation.Bean;
import org.springframework.context.annotation.Configuration;
import org.springframework.kafka.listener.DefaultErrorHandler;
import org.springframework.util.backoff.BackOff;
import org.springframework.util.backoff.FixedBackOff;

@Configuration
public class KafkaErrorHandlerConfig {
    
    @Bean
    public DefaultErrorHandler errorHandler() {
        // é‡è¯•ç­–ç•¥ï¼šæ¯ 1 ç§’é‡è¯•ä¸€æ¬¡ï¼Œæœ€å¤šé‡è¯• 3 æ¬¡
        BackOff backOff = new FixedBackOff(1000L, 3L);
        DefaultErrorHandler errorHandler = new DefaultErrorHandler(backOff);
        
        // é‡è¯•å¤±è´¥åï¼Œå‘é€åˆ°æ­»ä¿¡é˜Ÿåˆ—
        errorHandler.setCommitRecovered(true);
        
        return errorHandler;
    }
}
```

**ä½¿ç”¨é‡è¯•æœºåˆ¶**ï¼š

```java
import org.springframework.kafka.annotation.KafkaListener;
import org.springframework.kafka.listener.ConsumerSeekAware;
import org.springframework.stereotype.Component;

@Component
public class RetryConsumer implements ConsumerSeekAware {
    
    @KafkaListener(topics = "orders", groupId = "order-consumer-group",
                   errorHandler = "errorHandler")
    public void consumeOrder(String message) {
        // å¤„ç†æ¶ˆæ¯ï¼Œå¦‚æœå¤±è´¥ä¼šè‡ªåŠ¨é‡è¯•
        processOrder(message);
    }
    
    private void processOrder(String message) {
        // ä¸šåŠ¡å¤„ç†
    }
}
```

---

## 5. ç›‘æ§ä¸è¿ç»´

### 5.1 ç›‘æ§æŒ‡æ ‡

#### 5.1.1 Producer ç›‘æ§æŒ‡æ ‡

- **æ¶ˆæ¯å‘é€é€Ÿç‡** - messages-per-second
- **æ¶ˆæ¯å‘é€å»¶è¿Ÿ** - record-send-total, record-send-rate
- **å‘é€å¤±è´¥ç‡** - record-error-rate
- **æ‰¹æ¬¡å¤§å°** - batch-size-avg

#### 5.1.2 Consumer ç›‘æ§æŒ‡æ ‡

- **æ¶ˆæ¯æ¶ˆè´¹é€Ÿç‡** - records-consumed-rate
- **æ¶ˆè´¹å»¶è¿Ÿ** - records-lag-max
- **Offset æäº¤å»¶è¿Ÿ** - commit-latency-avg
- **é‡å¹³è¡¡æ¬¡æ•°** - rebalance-rate

### 5.2 å¸¸ç”¨è¿ç»´å‘½ä»¤

```bash
# æŸ¥çœ‹ Topic åˆ—è¡¨
bin/kafka-topics.sh --list --bootstrap-server localhost:9092

# æŸ¥çœ‹ Topic è¯¦æƒ…
bin/kafka-topics.sh --describe --topic orders --bootstrap-server localhost:9092

# æŸ¥çœ‹ Consumer Group åˆ—è¡¨
bin/kafka-consumer-groups.sh --list --bootstrap-server localhost:9092

# æŸ¥çœ‹ Consumer Group è¯¦æƒ…
bin/kafka-consumer-groups.sh --describe \
  --group my-consumer-group \
  --bootstrap-server localhost:9092

# æŸ¥çœ‹ Consumer Group çš„ Offset
bin/kafka-consumer-groups.sh --describe \
  --group my-consumer-group \
  --bootstrap-server localhost:9092 \
  --verbose

# é‡ç½® Consumer Group Offset
bin/kafka-consumer-groups.sh --reset-offsets \
  --group my-consumer-group \
  --topic orders \
  --to-earliest \
  --execute \
  --bootstrap-server localhost:9092
```

---

## 6. æœ€ä½³å®è·µ

### 6.1 Producer æœ€ä½³å®è·µ

1. **ä½¿ç”¨æ‰¹é‡å‘é€** - è®¾ç½® `batch.size` å’Œ `linger.ms`
2. **å¯ç”¨å‹ç¼©** - è®¾ç½® `compression.type=snappy` æˆ– `lz4`
3. **å¯ç”¨å¹‚ç­‰æ€§** - è®¾ç½® `enable.idempotence=true`
4. **åˆç†è®¾ç½® acks** - æ ¹æ®ä¸šåŠ¡éœ€æ±‚é€‰æ‹© `acks=all` æˆ– `acks=1`
5. **å¼‚æ­¥å‘é€** - ä½¿ç”¨å¼‚æ­¥å‘é€æé«˜ååé‡
6. **é”™è¯¯å¤„ç†** - å®ç° Callback å¤„ç†å‘é€å¤±è´¥

### 6.2 Consumer æœ€ä½³å®è·µ

1. **æ‰‹åŠ¨æäº¤ Offset** - è®¾ç½® `enable.auto.commit=false`
2. **æ‰¹é‡æ¶ˆè´¹** - è®¾ç½® `max.poll.records` å’Œæ‰¹é‡ç›‘å¬å™¨
3. **å¿«é€Ÿå¤„ç†** - é¿å…é•¿æ—¶é—´å¤„ç†å¯¼è‡´è¶…æ—¶
4. **å¹‚ç­‰æ€§å¤„ç†** - ä¿è¯æ¶ˆæ¯å¤„ç†çš„å¹‚ç­‰æ€§
5. **é”™è¯¯å¤„ç†** - å®ç°æ­»ä¿¡é˜Ÿåˆ—å’Œé‡è¯•æœºåˆ¶
6. **ç›‘æ§æ¶ˆè´¹å»¶è¿Ÿ** - ç›‘æ§ `records-lag-max` æŒ‡æ ‡

### 6.3 Topic è®¾è®¡æœ€ä½³å®è·µ

1. **åˆç†è®¾ç½® Partition æ•°é‡** - æ ¹æ®ååé‡å’Œ Consumer æ•°é‡
2. **è®¾ç½®å‰¯æœ¬å› å­** - `replication.factor>=3`
3. **è®¾ç½®ä¿ç•™æ—¶é—´** - æ ¹æ®ä¸šåŠ¡éœ€æ±‚è®¾ç½® `retention.ms`
4. **å‘½åè§„èŒƒ** - ä½¿ç”¨æœ‰æ„ä¹‰çš„ Topic åç§°
5. **é¿å…è¿‡å¤š Topic** - è¿‡å¤šçš„ Topic ä¼šå¢åŠ ç®¡ç†å¤æ‚åº¦

---

## 7. å¸¸è§é¢è¯•é¢˜

### Q1: Spring Boot å¦‚ä½•é›†æˆ Kafkaï¼Ÿ

**ç­”æ¡ˆè¦ç‚¹**ï¼š

1. **æ·»åŠ ä¾èµ–** - `spring-kafka`
2. **é…ç½®æ–‡ä»¶** - é…ç½® Producer å’Œ Consumer
3. **ä½¿ç”¨ KafkaTemplate** - å‘é€æ¶ˆæ¯
4. **ä½¿ç”¨ @KafkaListener** - æ¶ˆè´¹æ¶ˆæ¯
5. **é…ç½®åºåˆ—åŒ–å™¨** - JSONã€Avro ç­‰

### Q2: å¦‚ä½•ä¿è¯æ¶ˆæ¯ä¸ä¸¢å¤±ï¼Ÿ

**ç­”æ¡ˆè¦ç‚¹**ï¼š

1. **Producer ç«¯** - `acks=all`, `retries`, `enable.idempotence=true`
2. **Broker ç«¯** - `replication.factor>=3`, `min.insync.replicas>=2`
3. **Consumer ç«¯** - `enable.auto.commit=false`, æ‰‹åŠ¨æäº¤ Offset

### Q3: å¦‚ä½•å¤„ç†æ¶ˆæ¯é‡å¤æ¶ˆè´¹ï¼Ÿ

**ç­”æ¡ˆè¦ç‚¹**ï¼š

1. **å¹‚ç­‰æ€§å¤„ç†** - ä¿è¯ä¸šåŠ¡é€»è¾‘çš„å¹‚ç­‰æ€§
2. **å»é‡æœºåˆ¶** - ä½¿ç”¨ Redis æˆ–æ•°æ®åº“å»é‡
3. **å”¯ä¸€æ ‡è¯†** - ä½¿ç”¨æ¶ˆæ¯çš„å”¯ä¸€ ID å»é‡

### Q4: å¦‚ä½•æé«˜ Kafka çš„ååé‡ï¼Ÿ

**ç­”æ¡ˆè¦ç‚¹**ï¼š

1. **æ‰¹é‡å‘é€** - è®¾ç½® `batch.size` å’Œ `linger.ms`
2. **å‹ç¼©** - è®¾ç½® `compression.type`
3. **å¢åŠ  Partition** - æé«˜å¹¶è¡Œåº¦
4. **å¢åŠ  Consumer** - æé«˜æ¶ˆè´¹é€Ÿåº¦
5. **å¼‚æ­¥å‘é€** - ä½¿ç”¨å¼‚æ­¥å‘é€æé«˜ååé‡

---

## ğŸ“š æ‰©å±•é˜…è¯»

- [Spring Kafka å®˜æ–¹æ–‡æ¡£](https://docs.spring.io/spring-kafka/docs/current/reference/html/)
- [Kafka æœ€ä½³å®è·µ](https://kafka.apache.org/documentation/#bestpractices)
- [Confluent Platform](https://www.confluent.io/)

---

ğŸ’¡ **å­¦ä¹ æç¤º**ï¼šKafka å®æˆ˜åº”ç”¨éœ€è¦ç»“åˆå®é™…ä¸šåŠ¡åœºæ™¯ï¼Œå»ºè®®ä»ç®€å•çš„åœºæ™¯å¼€å§‹ï¼Œé€æ­¥æ·±å…¥ã€‚

ğŸ”„ æŒç»­æ›´æ–°ä¸­... | æœ€åæ›´æ–°ï¼š2025å¹´1æœˆ

